<h1 align="center">Hi ðŸ‘‹, I'm Gouravi Tandel from India</h1>
<h3 align="center">A passionate data science practitioner.</h3>

[Personal Website](https://https://medium.com/@gouraviTandel)

### I have completed

Courses: Python Programming, Statistics, Data Analysis & Visualization, Machine Learning, SQL & Analytics

Highlights: 600+ hours of coursework, 10 coding assignments, 3 projects (Web scraping, EDA, Tableau)

My Projects

**Exploratory Data Analysis of  7+ Million Company Dataset : [Link](https://jovian.ai/pankajthakur3999/eda-company-datasets) [Blog](https://blog.jovian.ai/exploratory-data-analysis-on-company-datasets-c331beaa28d0)**

* Cleaned data for 7+ million containing 11 columns and analyzed data by taking a sample of 10,000 rows using Pandas
* Created visualizations (scatter plots, Bar charts, Treemap, etc.) using Seaborn & Plotly
* Discovered United States is contributing to 53% of industries around the world and India is the 2nd largest country in IT industries.

**Web Scrapping of the Insurance Company [Link](https://jovian.ai/pankajthakur3999/web-scrapping-of-top-insurance-companies) [Blog](https://blog.jovian.ai/web-scraping-top-insurance-companies-using-python-and-beautifulsoup-9ec83bc5ab57)**

* Scrapped 526 Insurance companies from 53 pages of the same website value.today.
* The scrapping was done using python libraries such as Requests, Beautifulsoup, etc.
* The scrapped data was stored in a CSV file to be accessed for processing.

